{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The goal is to understand what factors influence whether a passenger survived the Titanic disaster. By analyzing passenger information such as age, gender, class, ticket, and fare, \n",
    "we want to find the variables had the strongest impact of the survivability. This will help make a model that can estimate the likelihood of survival for different types if passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The dataset was in the form of a csv file in a spreadsheet seperated by column for each attribute and by row for each passenger. It contains information such as name, age, gender, \n",
    "class, ticket, fare, family connections, and whether they survived or not.\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will need to check for missing values. Looking at patterns we see that factors like being a female, young, and first class had a higher survivability rate. Bias may include that\n",
    "survivability may correlate strongly with social or economic status, which shows inequalities based on social classes rather than pure chance.\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "#data analysis - survival percentages by category\n",
    "# survival by sex\n",
    "female_survival = df[df['Sex'] == 'female']['Survived'].mean()\n",
    "male_survival = df[df['Sex'] == 'male']['Survived'].mean()\n",
    "print(f\"Sex - Female: {female_survival:.3f}, Male: {male_survival:.3f}\")\n",
    "\n",
    "# survival by class\n",
    "class1_survival = df[df['Pclass'] == 1]['Survived'].mean()\n",
    "class2_survival = df[df['Pclass'] == 2]['Survived'].mean()\n",
    "class3_survival = df[df['Pclass'] == 3]['Survived'].mean()\n",
    "print(f\"Pclass - 1: {class1_survival:.3f}, 2: {class2_survival:.3f}, 3: {class3_survival:.3f}\")\n",
    "\n",
    "# survival by age\n",
    "young_survival = df[df['Age'] <= 18]['Survived'].mean()\n",
    "old_survival = df[df['Age'] > 18]['Survived'].mean()\n",
    "print(f\"Age - 18 and younger: {young_survival:.3f}, 18 and older: {old_survival:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I removed all the rows with missing values using X.dropna() to avoid errors, while we trained. Then, we converted sex into binary values 0 for male and 1 for female, so the Decesion Tree model could have\n",
    "a numeric representation. Finally, I selected key features focusing on sex, age, and Pclass since they are the most strongly correlated with survival. I did this to remove bias and take out irrelevant\n",
    "stuff.\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# prepare data\n",
    "X = df[['Sex', 'Age', 'Pclass']].copy()\n",
    "y = df['Survived']\n",
    "\n",
    "# remove rows with missing values\n",
    "X_clean = X.dropna().copy()\n",
    "y_clean = y.loc[X_clean.index]\n",
    "\n",
    "# encode categorical variable\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "X_clean.loc[:, 'Sex'] = X_clean['Sex'].map(sex_mapping)\n",
    "\n",
    "# split data intro training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I tried using different models such as Logistic Regression, Random Forest Classifier, and Decision Tree Classifier. Logistic Regression was simple and easy to understandm but it would only take into\n",
    "account two features, so it was less flexible and wasn't able to get high accuracy scores. Random Forst Classifier reduced overfitting, but was very hard to understand. The one I ended up going with was \n",
    "Decision Tree Classifier because it was easy to understand and handled multiple features.\n",
    "\n",
    "# train decision tree\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "# feature importance\n",
    "feature_names = ['Sex', 'Age', 'Pclass']\n",
    "importances = model.feature_importances_\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in zip(feature_names, importances):\n",
    "    print(f\"{name}: {importance:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Clean data\n",
    "2. Select model based on comparison and usefulness for current project\n",
    "2. Select features that work best like sex, age, and pclass\n",
    "3. Tested different maximum depths, criterions(gini and entropy)\n",
    "4. Used multiple data splits to avoid random luck in one test/train split\n",
    "5. Fine tuned model using accuracy, precision, recall, and feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The analysis of titanic passenger data shows that gender, passenger class, and age were the most important factors in determining survival. Women and children, especially in first and second class,\n",
    "had much higher survival rates compared to men in third class. We experimented with multiple machine learning models. Logistic Regression provided a simple baseline. A Decision Tree gave clear rules \n",
    "for survival predictions. Random Forest Classifier was too complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "Sex - Female: 0.742, Male: 0.189\n",
      "Pclass - 1: 0.630, 2: 0.473, 3: 0.242\n",
      "Age - 18 and younger: 0.504, 18 and older: 0.383\n",
      "Test Accuracy: 0.776\n",
      "\n",
      "Feature Importance:\n",
      "Sex: 0.425\n",
      "Age: 0.404\n",
      "Pclass: 0.170\n",
      "\n",
      "Example: Sex=male, Age=42, Pclass=2 -> Not Survived\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def titanic():\n",
    "    # dataset loading\n",
    "    df = pd.read_csv(\"titanic.csv\")\n",
    "    \n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    print(df.head())\n",
    "    \n",
    "    \n",
    "    # data analysis - survival percentages by category\n",
    "    # survival by sex\n",
    "    female_survival = df[df['Sex'] == 'female']['Survived'].mean()\n",
    "    male_survival = df[df['Sex'] == 'male']['Survived'].mean()\n",
    "    print(f\"Sex - Female: {female_survival:.3f}, Male: {male_survival:.3f}\")\n",
    "    \n",
    "    # survival by class\n",
    "    class1_survival = df[df['Pclass'] == 1]['Survived'].mean()\n",
    "    class2_survival = df[df['Pclass'] == 2]['Survived'].mean()\n",
    "    class3_survival = df[df['Pclass'] == 3]['Survived'].mean()\n",
    "    print(f\"Pclass - 1: {class1_survival:.3f}, 2: {class2_survival:.3f}, 3: {class3_survival:.3f}\")\n",
    "    \n",
    "    # survival by age\n",
    "    young_survival = df[df['Age'] <= 18]['Survived'].mean()\n",
    "    old_survival = df[df['Age'] > 18]['Survived'].mean()\n",
    "    print(f\"Age - 18 and younger: {young_survival:.3f}, 18 and older: {old_survival:.3f}\")\n",
    "    \n",
    "    # prepare data\n",
    "    X = df[['Sex', 'Age', 'Pclass']].copy()\n",
    "    y = df['Survived']\n",
    "    \n",
    "    # remove rows with missing values\n",
    "    X_clean = X.dropna().copy()\n",
    "    y_clean = y.loc[X_clean.index]\n",
    "    \n",
    "    # encode categorical variable\n",
    "    sex_mapping = {'male': 0, 'female': 1}\n",
    "    X_clean.loc[:, 'Sex'] = X_clean['Sex'].map(sex_mapping)\n",
    "    \n",
    "    # split data intro training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # train decision tree\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "    \n",
    "    # feature importance\n",
    "    feature_names = ['Sex', 'Age', 'Pclass']\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    for name, importance in zip(feature_names, importances):\n",
    "        print(f\"{name}: {importance:.3f}\")\n",
    "    \n",
    "    # Example with test data\n",
    "    test_sample = X_test.iloc[0]\n",
    "    prediction = model.predict(test_sample.to_frame().T)[0]\n",
    "    reverse_sex_mapping = {0: 'male', 1: 'female'}\n",
    "    print(f\"\\nExample: Sex={reverse_sex_mapping[test_sample['Sex']]}, Age={test_sample['Age']:.0f}, Pclass={test_sample['Pclass']} -> {'Survived' if prediction == 1 else 'Not Survived'}\")\n",
    "\n",
    "\n",
    "titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
