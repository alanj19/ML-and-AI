{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, your team is having difficulty on narrowing down the specific groups that should be targeted who are more likely to buy a cog. By looking at past customer information such as age, salary range, gender, and whether they purchased it or not, I want to find patterns to show who will and won't buy cogs. Once these patterns are found a model can be created to allow your team to target the correct audience, improve efficiency, and increase sales success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was provided directly from the customer in the form of a CSV file. This dataset contains details about 1000 customers such as customer age, gender, estimated salary, and whether or not they purchased or returned a cog. This data is our starting point and provides us the raw information we need to analyze patterns and build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID              name  Gender  Age  EstimatedSalary  Purchased\n",
      "0    10000     Angela Davila    Male   23            19075          0\n",
      "1    10001     John Mckinney    Male   31           147946          1\n",
      "2    10002  Maureen Williams  Female   50            16690          0\n",
      "3    10003  Stephanie Duarte  Female   33           133474          0\n",
      "4    10004    Rebecca Graves  Female   54            75928          1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          1001 non-null   int64 \n",
      " 1   name             1001 non-null   object\n",
      " 2   Gender           1001 non-null   object\n",
      " 3   Age              1001 non-null   int64 \n",
      " 4   EstimatedSalary  1001 non-null   int64 \n",
      " 5   Purchased        1001 non-null   int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 47.0+ KB\n",
      "None\n",
      "            User ID          Age  EstimatedSalary    Purchased\n",
      "count   1001.000000  1001.000000      1001.000000  1001.000000\n",
      "mean   10500.000000    39.942058     79097.413586     0.426573\n",
      "std      289.108111    11.539958     40579.725320     0.568202\n",
      "min    10000.000000    20.000000      8406.000000    -1.000000\n",
      "25%    10250.000000    31.000000     43392.000000     0.000000\n",
      "50%    10500.000000    40.000000     79114.000000     0.000000\n",
      "75%    10750.000000    50.000000    112440.000000     1.000000\n",
      "max    11000.000000    59.000000    149574.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Project_3.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purchases are split between 50% not purchased, 46% purchased, and 4% returned. Middle-aged customer from 35-50 purchase at the highest rate, while younger customers from 20-30 are less likely. The highest salarites correlate with higher purchase rates. Gender is balanced with around 50/50. There may be bias because there are very few returned cases, so the model may not get much from the returns. There are also some mismatched gender labels that might slightly affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bias Summary:\n",
      "{'gender_distribution': {'Male': 0.5044955044955045, 'Female': 0.4955044955044955}, 'age_distribution': {'count': 1001.0, 'mean': 39.94205794205794, 'std': 11.539958377768931, 'min': 20.0, '25%': 31.0, '50%': 40.0, '75%': 50.0, 'max': 59.0}, 'purchase_distribution': {0: 0.4955044955044955, 1: 0.46553446553446554, -1: 0.03896103896103896}}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "status_map = {-1: 'Returned', 0: 'Not Purchased', 1: 'Purchased'}\n",
    "df['Purchase_Status_Label'] = df['Purchased'].map(status_map)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Purchase_Status_Label', data=df, palette='Set2')\n",
    "plt.title(\"Distribution of Purchase Status\")\n",
    "plt.xlabel(\"Purchase Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(data=df, x='Age', hue='Purchase_Status_Label',\n",
    "             multiple='stack', bins=20, palette='Set2')\n",
    "plt.title(\"Age Distribution by Purchase Status\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='Purchase_Status_Label', y='EstimatedSalary',\n",
    "            data=df, palette='Set2')\n",
    "plt.title(\"Estimated Salary by Purchase Status\")\n",
    "plt.xlabel(\"Purchase Status\")\n",
    "plt.ylabel(\"Estimated Salary\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Gender', hue='Purchase_Status_Label',\n",
    "              data=df, palette='Set2')\n",
    "plt.title(\"Gender vs Purchase Status\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "bias_summary = {\n",
    "    \"gender_distribution\": df['Gender'].value_counts(normalize=True).to_dict(),\n",
    "    \"age_distribution\": df['Age'].describe().to_dict(),\n",
    "    \"purchase_distribution\": df['Purchased'].value_counts(normalize=True).to_dict()\n",
    "}\n",
    "\n",
    "print(\"\\nBias Summary:\")\n",
    "print(bias_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean the data I dropped irrelevant colunms like UserID and name since they don't help prediction. Then, I split the purchased column into 3 features: -1 = returned, 0 = not purchased, 1 = purchased. Then, I converted gender into numeric labels 1 for male and 0 for female. Then, I handled the imbalance using SMOTE, which creates synthetic data points to balance all purchase categories evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Balance Before SMOTE:\n",
      "Purchase_Status\n",
      " 0    496\n",
      " 1    466\n",
      "-1     39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Balance After SMOTE:\n",
      "Purchase_Status\n",
      " 0    496\n",
      " 1    496\n",
      "-1    496\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_clean = df.drop(columns=[\"User ID\", \"name\", \"Purchase_Status_Label\"], errors=\"ignore\")\n",
    "\n",
    "# Rename target column\n",
    "df_clean = df_clean.rename(columns={\"Purchased\": \"Purchase_Status\"})\n",
    "\n",
    "# Convert any mislabelled target values (ensure -1, 0, 1)\n",
    "df_clean[\"Purchase_Status\"] = df_clean[\"Purchase_Status\"].replace({2: -1}).astype(int)\n",
    "\n",
    "# Encode Gender\n",
    "le = LabelEncoder()\n",
    "df_clean[\"Gender\"] = le.fit_transform(df_clean[\"Gender\"])\n",
    "\n",
    "# Drop missing values\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "# Define features and target\n",
    "X = df_clean.drop(columns=[\"Purchase_Status\"])\n",
    "y = df_clean[\"Purchase_Status\"]\n",
    "\n",
    "print(\"\\nClass Balance Before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Balance data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nClass Balance After SMOTE:\")\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained and compared 4 different models to predict purchase behavior. Logistic Regression got the lowest accuracy at about 44%, then Random Forest got an accuracy of about 49%, and finally my best one was Gradient Boosting, which got an accuracy of about 53%. This is not that strong of an accuracy, but it is the best that I got after tweaking it, but I blame the lack of quality and patterns in the data for the flipping a coin accuracy. I also tried XGboost, but still only got an accuracy of 52%, which is the second highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.82      0.58        99\n",
      "           0       0.45      0.33      0.38        99\n",
      "           1       0.42      0.18      0.25       100\n",
      "\n",
      "    accuracy                           0.44       298\n",
      "   macro avg       0.44      0.44      0.40       298\n",
      "weighted avg       0.44      0.44      0.40       298\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.67      0.66        99\n",
      "           0       0.42      0.41      0.42        99\n",
      "           1       0.39      0.38      0.38       100\n",
      "\n",
      "    accuracy                           0.49       298\n",
      "   macro avg       0.48      0.49      0.49       298\n",
      "weighted avg       0.48      0.49      0.49       298\n",
      "\n",
      "\n",
      "--- Gradient Boosting (Baseline) ---\n",
      "Accuracy: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.79      0.71        99\n",
      "           0       0.47      0.39      0.43        99\n",
      "           1       0.42      0.40      0.41       100\n",
      "\n",
      "    accuracy                           0.53       298\n",
      "   macro avg       0.51      0.53      0.52       298\n",
      "weighted avg       0.51      0.53      0.52       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    return acc, preds\n",
    "\n",
    "# Evaluate all models\n",
    "acc_lr, preds_lr = evaluate_model(log_reg, X_test, y_test, \"Logistic Regression\")\n",
    "acc_rf, preds_rf = evaluate_model(rf, X_test, y_test, \"Random Forest\")\n",
    "acc_gb, preds_gb = evaluate_model(gb, X_test, y_test, \"Gradient Boosting (Baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Model\n",
      "Accuracy: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.75      0.70        99\n",
      "           0       0.45      0.40      0.43        99\n",
      "           1       0.42      0.41      0.42       100\n",
      "\n",
      "    accuracy                           0.52       298\n",
      "   macro avg       0.51      0.52      0.51       298\n",
      "weighted avg       0.51      0.52      0.51       298\n",
      "\n",
      "\n",
      "XGBoost training failed: name 'confusion_matrix' is not defined\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "try:\n",
    "    y_train_xgb = y_train + 1\n",
    "    y_test_xgb = y_test + 1\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        random_state=42,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=300,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=3\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train_xgb)\n",
    "\n",
    "    xgb_preds_shifted = xgb_model.predict(X_test)\n",
    "    xgb_preds = xgb_preds_shifted - 1\n",
    "\n",
    "    acc_xgb = accuracy_score(y_test, xgb_preds)\n",
    "\n",
    "    print(\"\\nXGBoost Model\")\n",
    "    print(f\"Accuracy: {acc_xgb:.2f}\")\n",
    "    print(classification_report(y_test, xgb_preds))\n",
    "    print(confusion_matrix(y_test, xgb_preds))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nXGBoost training failed:\", e)\n",
    "    acc_xgb = 0\n",
    "    xgb_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used GridSearchCV, which tests multiple parameter combos, to find the best config for Gradient Boosting. The model was tuned for learning rate, estimators, and tree depth. The best result after tuning was at 52%, which is lower than the model before tuning sadly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running GridSearchCV for Gradient Boosting...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "‚úÖ Best Parameters Found: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "Tuned Gradient Boosting Accuracy: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.82      0.74        99\n",
      "           0       0.40      0.35      0.37        99\n",
      "           1       0.43      0.39      0.41       100\n",
      "\n",
      "    accuracy                           0.52       298\n",
      "   macro avg       0.50      0.52      0.51       298\n",
      "weighted avg       0.50      0.52      0.51       298\n",
      "\n",
      "\n",
      "==================== Final Model Comparison ====================\n",
      "Logistic Regression Accuracy: 0.44\n",
      "Random Forest Accuracy:       0.49\n",
      "Gradient Boosting (Baseline): 0.53\n",
      "Gradient Boosting (Tuned):    0.52\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameter grid for Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_gb = grid_search.best_estimator_\n",
    "print(\"\\nBest Parameters Found:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_preds = best_gb.predict(X_test)\n",
    "acc_best = accuracy_score(y_test, best_preds)\n",
    "print(f\"\\nTuned Gradient Boosting Accuracy: {acc_best:.2f}\")\n",
    "print(classification_report(y_test, best_preds))\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.2f}\")\n",
    "print(f\"Random Forest Accuracy:       {acc_rf:.2f}\")\n",
    "print(f\"Gradient Boosting (Baseline): {acc_gb:.2f}\")\n",
    "print(f\"Gradient Boosting (Tuned):    {acc_best:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis showed that age and estimated salary are the strongest predictors of whether a customer will purchase a cog, with middle-aged and higher-income customers being the most likely buyers. The gender distribution in the dataset was well-balanced, meaning the model was not influenced by gender bias in its predictions. After cleaning the data, correcting mislabeled entries, and balancing the classes, several models were tested ‚Äî including Logistic Regression, Random Forest, Gradient Boosting, and XGBoost. Among them, Gradient Boosting achieved the best performance with an accuracy between 0.53, making it the most reliable model for predicting customer purchase behavior. This model provides valuable insights that can help the sales team identify high-potential customers, target marketing efforts more effectively, and ultimately increase sales efficiency by focusing resources where purchases are most likely to occur. However, the accuracy is not up to par, so we would love to receive more data or even more features to see if we could boost the accuracy and best find how to increase sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Purchased\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model = joblib.load(\"model.pkl\")\n",
    "\n",
    "def inference(params):\n",
    "\n",
    "    input_df = pd.DataFrame([params])\n",
    "    result = model.predict(input_df)[0]\n",
    "\n",
    "    if int(result) == 1:\n",
    "        return \"Purchased\"\n",
    "    elif int(result) == 0:\n",
    "        return \"Not Purchased\"\n",
    "    else:\n",
    "        return \"Returned\"\n",
    "        \n",
    "example = {\n",
    "    \"Gender\": 1,  \n",
    "    \"Age\": 40,\n",
    "    \"EstimatedSalary\": 70000\n",
    "}\n",
    "\n",
    "print(\"Prediction:\", inference(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
