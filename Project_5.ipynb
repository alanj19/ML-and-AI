{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to develop a system that can look at images of handwritten cursive letters and accurately identify which letter each image represents. The customer wants a tool that can process many different handwritten samples, including different handwriting styles, and automatically recognize each letter the image is showing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was provided as a zip file containing around 30 samples of cursive letter a through z with the folder seperated by student who wrote each letter and file name signifying the letter. The fact that the dataset is handwritten images will make recognition more challenging due to the natural variations in handwriting style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All HEIC images converted to JPG and saved in: converted_images\n"
     ]
    }
   ],
   "source": [
    "import zipfile, os\n",
    "from pillow_heif import register_heif_opener\n",
    "from PIL import Image\n",
    "\n",
    "zip_path = \"images.zip\"\n",
    "extract_path = \"extracted_images\"\n",
    "converted_path = \"converted_images\"\n",
    "\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "print(\"All images extracted.\")\n",
    "\n",
    "\n",
    "register_heif_opener()\n",
    "os.makedirs(converted_path, exist_ok=True)\n",
    "\n",
    "for root, _, files in os.walk(extract_path):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".heic\"):\n",
    "            heic_path = os.path.join(root, f)\n",
    "            rel_dir = os.path.relpath(root, extract_path)\n",
    "            target_dir = os.path.join(converted_path, rel_dir)\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "            jpg_path = os.path.join(target_dir, f.rsplit('.', 1)[0] + \".jpg\")\n",
    "            with Image.open(heic_path) as img:\n",
    "                img.convert(\"L\").resize((64, 64)).save(jpg_path, \"JPEG\", quality=85, optimize=True)\n",
    "\n",
    "print(\"All HEIC images converted to JPG (Aâ€“Z structure preserved).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the zip file, I explored the dataset and verified the number of samples per letter. Each letter had a varying amount as there were some duplicates of letters and each folder was formatted in a weird way, so most likely I will have to remove all subfolders and make it one big folder with each image named after the letter it is. I will also have to crop some images to just see the paper it is written on because some are very zoomed out, which will make it difficult to detect the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(\"converted_images\"):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root).lower()\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "data = np.array(data).reshape(-1, 64, 64, 1) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Loaded {len(data)} images from {len(np.unique(labels))} letter folders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I prepared the handwritten cursive letter images for modeling. I will seperate it into subfolders respresenting each letter. I loaded every image, resized it to a consistent 200x200, and converted it to grayscale so that the model will focus more on shape then color. The pixel values were normalized to 0-1 scale to ensure consistency. The folder names will be used as labels, when the data is encoded into numerical values and then one-hot encoded so they can be used for classification later. Then the data was split into 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = \"converted_images\"\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(root, f)\n",
    "            label = os.path.basename(root).lower() \n",
    "\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (64, 64)) \n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "data = np.array(data).reshape(-1, 64, 64, 1)  \n",
    "labels = np.array(labels)\n",
    "\n",
    "data = data.astype(\"float32\") / 255.0\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(labels)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical\n",
    ")\n",
    "\n",
    "print(f\"Total images: {len(data)}\")\n",
    "print(f\"Letters (classes): {len(np.unique(labels))}\")\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
